# The Hyperdimensional Resonator

The body is amassed with electrical signals. These bioelectric signals are tied
to both the most basic body functions such as the heart beating all the way to
the highest level of processing in the brain. These signals are often rhythmic
in nature and provide a means to measure the fundamental rhythms of any
individual. In this performance we will generate music in real time from
bioelectric signals that are read from a human subject. The ECG (heart) will set
the rhythm of the music while other signals including EEG (brain waves) and EMG
(muscles) will be used by an algorithm to perform melodic and rhythmic choices.
The subject will participate by dancing and responding to the generated music
and by virtue of their interaction will change the music produced. Additionally,
the signals will be sonified and form part of the music. Musician(s) will also
improvise along with the generated music with their instruments being modulated
by the captured bioelectric signals.

## Technical Rider

Multiple output channels (up to 8) will be supplied from a computer audio
interface. These will be on simple unbalanced TR connections

Stage or performance space for one to two musicians. Electric guitars will be
used in the performance and amplified using standard guitar amplifiers. These
will need to be miked and fed through the PA system (depending on venue size).

## Artist Profile

Matthew Walsh is a musician, software engineer and neuroscientist, obtaining a
PhD in Computational Neuroscience in 2020. His thesis topic was “Mean Field
Modelling of Epileptogenic Cortical Lesions Using The Liley Model”. This thesis
focussed on modelling the effects of cortical lesions on the EEG. Matthew has
now broadened his research interests to include the sonification and
musification of biological signals.

Matthew is vocalist, guitarist and songwriter for the Melbourne band “Your Creepy Ex”.

## Examples

Examples of the musification of biological signals (both EEG and ECG) using the
technique that is intended to be used at the AlgoRave can be found at the
following dropbox link.

<https://www.dropbox.com/sh/2d7bcn2svestqd5/AAB_lc6P5CgH6cqMaVjv3Mzia?dl=0>

The music in these examples is entirely algorithmically produced from data
recorded from epileptic patients experiencing epileptic seizures and other
epileptic events.
